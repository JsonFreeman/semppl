var questionStartSymbol = "$WH";
var answerStartSymbol = "$S";
// Change the name to parse to test model in isolation
var dummyParse = function(utterance) {
    if (utterance === ">0")
        return function(w) { return w.x > 0 ? 1 : 0; };
    if (utterance === "=0")
        return function(w) { return w.x === 0 ? 1 : 0; };
    if (utterance === "=1")
        return function(w) { return w.x === 1 ? 1 : 0; };
    if (utterance === "=2")
        return function(w) { return w.x === 2 ? 1 : 0; };
    if (utterance === "!=1")
        return function(w) { return w.x !== 1 ? 1 : 0; };
    if (utterance === ">0?")
        return function (w) { 
            return function(t) { return (w.x > 0) === t ? 1 : 0; };
        }
    if (utterance === "=0?")
        return function (w) { 
            return function(t) { return (w.x === 0) === t ? 1 : 0; };
        }
    if (utterance === "=1?")
        return function (w) { 
            return function(t) { return (w.x === 1) === t ? 1 : 0; };
        }
    if (utterance === "=2?")
        return function (w) { 
            return function(t) { return (w.x === 2) === t ? 1 : 0; };
        }
};

var KL = function(p, q){
    return expectation(p, function(value) {
        var scoreP = p.score(value);
        var scoreQ = q.score(value);
        return scoreP === -Infinity ? 0 : scoreP - scoreQ;
    });
};

var interpretAnswer = function(worldPrior, answer, parser) {
    var answerMeaning = parser(answer, 0, answerStartSymbol);
    return Infer({method: 'enumerate'}, function() {
        var world = sample(worldPrior);
        factor(Math.log(answerMeaning(world)));
        return world;
    });
}

var similarity = function(trueWorldPredicate, otherWorldPredicate, domain) {
    // trueWorldPredicate and otherWorldPredicate are each distributions
    // over subsets of the domain. Compute KL between them using factorization
    // for sequence of independent bernoulli trials.
    return Math.exp(-sum(map(function(e) {
        var p_e = trueWorldPredicate(e);
        var q_e = otherWorldPredicate(e);
        var positiveTerm = p_e === 0 ? 0 : p_e * Math.log(p_e / q_e);
        var negativeTerm = p_e === 1 ? 0 : (1 - p_e) * Math.log((1 - p_e) / (1 - q_e));
        return positiveTerm + negativeTerm;
    }, domain)));
}

var answerQualityForQuestion = function(worldPrior, answer, questionPredicate, trueWorld, parser) {
    // Using soft similarity semantics
    var consistentWorlds = interpretAnswer(worldPrior, answer, parser);
    return Math.log(expectation(consistentWorlds, function(w) {
        assert.ok(w.domain.length === trueWorld.domain.length)
        var truePredicate = questionPredicate(trueWorld);
        var otherPredicate = questionPredicate(w);
        return similarity(truePredicate, otherPredicate, trueWorld.domain);
    }))
}

var answerQualityForQud = function(worldPrior, answer, qud, trueWorld, parser) {
    // Using hard partition semantics
    var consistentWorlds = interpretAnswer(worldPrior, answer, parser);
    return marginalize(consistentWorlds, qud).score(qud(trueWorld));
}

var costFn = constF(1);

var sampleUtterance = function(utterances) {
    return categorical(map(costFn, utterances), utterances);
}

var createVariationalModel = function(questions, answers, worldPrior, qudCandidates, 
                                      rationality, grammar, predicates, observationFn, opts) {
    return sample(OptimizeThenSample(function() {
        var parser = createParser(grammar, makeModelParams(grammar, predicates, /*hiddenSize*/ 10));
        var model = createModel(questions, answers, worldPrior, qudCandidates, rationality, parser);
        if (observationFn) {
            observationFn(model);
        }
        return model;
    }, opts));
}

var createModel = function(questions, answers, worldPrior, qudCandidates, rationality, parser) {
    var informationGain = function(question, qudFn, trueWorld, answerer) {
        var prior = marginalize(worldPrior, qudFn);
        var answerDist = answerer(question, trueWorld);
        var posterior = Infer({method: 'enumerate'}, function() {
            var answer = sample(answerDist);
            var world = sample(interpretAnswer(worldPrior, answer, parser));
            return qudFn(world);
        });

        return KL(posterior, prior);
    }

    var explicitAnswerer = function(question, trueWorld) {
        var questionMeaning = parser(question, 0, questionStartSymbol);
        return Infer({method: 'enumerate'}, function() {
            var answer = sampleUtterance(answers);
            var answerMeaning = parser(answer, 0, answerStartSymbol);
            factor(Math.log(answerMeaning(trueWorld)) * rationality);
            factor(answerQualityForQuestion(worldPrior, answer, questionMeaning, trueWorld, parser)
                * rationality);
            return answer;
        })
    }

    var questioner = function(answerer) {
        return function(qudFn) {
            return Infer({method: 'enumerate'}, function() {
                var question = sampleUtterance(questions);
                var expectedInformationGain = expectation(worldPrior, function(world) {
                    return informationGain(question, qudFn, world, answerer);
                });
                factor(expectedInformationGain * rationality);
                return question;
            });
        }
    }

    var pragmaticAnswerer = function(question, trueWorld) {
        var explicitQuestioner = questioner(explicitAnswerer);
        return Infer({method: 'enumerate'}, function() {
            var qud = uniformDraw(qudCandidates);
            var questionDist = explicitQuestioner(qud);
            var answer = sampleUtterance(answers);
            factor((questionDist.score(question)
                    + answerQualityForQud(worldPrior, answer, qud, trueWorld, parser))
                    * rationality);
            return answer;
        });
    }

    var explicitQuestioner = questioner(explicitAnswerer);
    var pragmaticQuestioner = questioner(pragmaticAnswerer);

    return { Q1: explicitQuestioner, A1: explicitAnswerer, Q2: pragmaticQuestioner, A2: pragmaticAnswerer };
}

// Testing

var testExplicitQuestioner = function() {
    var questions = [">0?", "=1?"];
    var answers = [">0", "=0", "=1", "!=1"]
    var worlds = [{ x: 0 }, { x: 1 }, { x: 2 }];
    var qudCandidates = [function (w) { return w.x > 0 }, function (w) { return w.x === 1 }, idF]
    var explicitQuestioner = createModel(questions, answers, 1, null).Q1; // Use dummyParse
    display(explicitQuestioner(
        Categorical({vs: worlds, ps: repeat(worlds.length, constF(1))}),
        qudCandidates[2], qudCandidates))
}

// testExplicitQuestioner();

var testSimilarityFunction = function() {
    var length = 5;
    var domain = _.range(0, length);
    var dist1 = repeat(length, function() { uniform(0, 1) });
    var dist2 = repeat(length, function() { uniform(0, 1) });
    var index = function(dist) { 
        return function (element) { dist[element] }
    }
    var sim = -Math.log(similarity(index(dist1), index(dist2), domain));

    var makeJointDist = function(dist) {
        return Infer({method: 'enumerate'}, function() {
            return map(bernoulli, dist);
        })
    }
    var kl = KL(makeJointDist(dist1), makeJointDist(dist2));

    assert.strictEqual(sim.toFixed(10), kl.toFixed(10));
}

// testSimilarityFunction();
var testIntegratedAnswerers = function() {
    var questions = ["Who is a doctor", "Who is a teacher", "Who is a fisherman"]
    var answers = ["John is a doctor", "John is a teacher", "John is a fisherman",
                      "John and Mary is a doctor", "John and Mary is a teacher", "John and Mary is a fisherman"]
    var worlds = [  { domain: ["john", "mary"], facts: { doctor: ["john"], teacher: [], fisherman: []}},
                    { domain: ["john", "mary"], facts: { doctor: [], teacher: ["john"], fisherman: []}},
                    { domain: ["john", "mary"], facts: { doctor: [], teacher: [], fisherman: ["john"]}},
                    { domain: ["john", "mary"], facts: { doctor: ["john", "mary"], teacher: [], fisherman: []}},
                    { domain: ["john", "mary"], facts: { doctor: [], teacher: ["john", "mary"], fisherman: []}},
                    { domain: ["john", "mary"], facts: { doctor: [], teacher: [], fisherman: ["john", "mary"]}},]
    var qudCandidates = [function(w) { w.facts.teacher }]
    var testIntegratedAnswerer = function(answerer) {
        var trueWorld = worlds[2];
        var question = questions[1];
        display(answerer(question, trueWorld))
    }

    var model = sample(SampleGuide(
        createVariationalModel(questions, answers, 
            Categorical({vs: worlds, ps: repeat(worlds.length, constF(1))}), qudCandidates, 1, 
            semppl.neuralPredicateGrammar, ['doctor', 'teacher', 'fisherman'])));
    testIntegratedAnswerer(model.A1)
    testIntegratedAnswerer(model.A2)
}

// testIntegratedAnswerers();

var testGenerateData = function() {
    var questions = ["Who is a doctor", "Who is a teacher", "Who is a fisherman"]
    var answers = ["John is a doctor", "John is a teacher", "John is a fisherman",
                      "John and Mary is a doctor", "John and Mary is a teacher", "John and Mary is a fisherman"]
    var worlds = [  { domain: ["john", "mary"], facts: { doctor: ["john"], teacher: [], fisherman: []}},
                    { domain: ["john", "mary"], facts: { doctor: [], teacher: ["john"], fisherman: []}},
                    { domain: ["john", "mary"], facts: { doctor: [], teacher: [], fisherman: ["john"]}},
                    { domain: ["john", "mary"], facts: { doctor: ["john", "mary"], teacher: [], fisherman: []}},
                    { domain: ["john", "mary"], facts: { doctor: [], teacher: ["john", "mary"], fisherman: []}},
                    { domain: ["john", "mary"], facts: { doctor: [], teacher: [], fisherman: ["john", "mary"]}},]
    var qudCandidates = [function(w) { w.facts.teacher }];
    var model = createModel(questions, answers, Categorical({ vs: worlds, ps: ones([worlds.length]).toFlatArray() }),
        qudCandidates, 1, createParser(semppl.fixedGrammar, []));
    generateTrainingData([questions, answers, worlds, qudCandidates], function(q, a, w, qud) {
        return apply(model.A1, [q, w]);
    }, 5);
}

// testGenerateData();

var testOptimize = function() {
    var questions = ["Who is a doctor", "Who is a teacher", "Who is a fisherman"]
    var answers = ["John is a doctor", "John is a teacher", "John is a fisherman",
                      "John and Mary is a doctor", "John and Mary is a teacher", "John and Mary is a fisherman"]
    var worlds = [  { domain: ["john", "mary"], facts: { doctor: ["john"], teacher: [], fisherman: []}},
                    { domain: ["john", "mary"], facts: { doctor: [], teacher: ["john"], fisherman: []}},
                    { domain: ["john", "mary"], facts: { doctor: [], teacher: [], fisherman: ["john"]}},
                    { domain: ["john", "mary"], facts: { doctor: ["john", "mary"], teacher: [], fisherman: []}},
                    { domain: ["john", "mary"], facts: { doctor: [], teacher: ["john", "mary"], fisherman: []}},
                    { domain: ["john", "mary"], facts: { doctor: [], teacher: [], fisherman: ["john", "mary"]}},]
    var qudCandidates = [function(w) { w.facts.teacher }];
    var data = repeat(100, function() {
        return [questions[0], answers[0], worlds[0]];
    })
    var model = createVariationalModel(questions, answers, Categorical({ vs: worlds, ps: ones([worlds.length]).toFlatArray() }),
        qudCandidates, 1, semppl.neuralPredicateGrammar, ['doctor', 'teacher', 'fisherman'], function(model) {
            mapData({ data: data, batchSize: 10 }, function(d) {
                observe(apply(model.A1, [d[0], d[2]]), d[1]);
            })
        }, 
        { optimizer: 'adam', steps: 10, estimator: 'ELBO' });
    apply(model.A1, [questions[0], worlds[0]]);
}

// testOptimize();