var featureFn = function (d) { return semppl.ruleFeatureFn(d); };
var scoreFn = function (features, params) {
    return sum(_.values(mapObject(function (k, v) {
        return _.has(params, k) ? v * params[k] : 0;
    }, features)));
};

var normalize = function (array) {
    var s = sum(array);
    return map(function (x) {
        return x / s;
    }, array);
};

var getSemantics = function (world) {
    return function (derivation) {
        return derivation.semantics(world);
    };
};

var marginalizeDerivationsForAssertion = function(derivationProbabilities, semantics) {
    return sum(map2(function (derivation, truth) {
        return derivation * truth;
    }, derivationProbabilities, semantics));
}

var marginalizeDerivationsForQuestion = function(derivationProbabilities, semantics) {
    return function(element) {
        return sum(map2(function (derivation, truthFn) {
            // truthFn was returned by the parser, so need to call it as a js function
            return derivation * truthFn.call(null, element);
        }, derivationProbabilities, semantics));
    }
}

var createParser = function (grammar, params) {
    var parser = semppl.createParser(grammar, params, semppl.ruleFeatureFn);
    return cache(function (utterance, theta, startSymbol) {
        // Need to use .call to call parser as a js function
        var chart = parser.call(null, utterance, theta);
        var rootCellDerivations = semppl.getRootCellDerivations(chart, startSymbol);

        assert.ok(chart && rootCellDerivations && rootCellDerivations.length > 0,
            "Cannot parse utterance '" + utterance + "' with startSymbol " + startSymbol)
        // Gather the two relevant probabilities
        var derivationProbabilities = normalize(map(function (d) {
            return Math.exp(scoreFn(featureFn(d), params.parserWeights));
        }, rootCellDerivations));

        var marginalizationFunction = startSymbol === "$S" ? marginalizeDerivationsForAssertion :
                                      startSymbol === "$WH" ? marginalizeDerivationsForQuestion :
                                      null;

        return cache(function (world) {
            // World dependent part starts here.
            var semantics = map(getSemantics(world), rootCellDerivations);

            // We now have probabilities that the sentences are true given derivations P(t | d)
            // Also probabilities that derivations are correct P(d)

            return marginalizationFunction(derivationProbabilities, semantics);
        });
    });
}

var createParserWeights = function (grammar) {
    return _.fromPairs(map(function (entry) {
        var name = semppl.makeRuleKey(entry);
        return [
            name, // key
            modelParam({ mu: 0, name: name }) // value
        ];
    }, grammar));
};

var createNetworkParams = function (hiddenSize, inputSize, predicate) {
    var W0 = modelParam({ dims: [hiddenSize, inputSize], mu: 0, sigma: 0.1, name: predicate + "W0"})
    var W1 = modelParam({ dims: [1, hiddenSize], mu: 0, sigma: 0.1, name: predicate + "W1" })
    var b0 = modelParam({ dims: [hiddenSize, 1], mu: 0, sigma: 0.1, name: predicate + "b0" })
    var b1 = modelParam({ dims: [1, 1], mu: 0, sigma: 0.1, name: predicate + "b1" })

    return { W: [W0, W1], b: [b0, b1] };
}

var makeModelParams = function(grammar, predicates, hiddenSize) {
    return {
        parserWeights: createParserWeights(grammar),
        networkParams: _.zipObject(predicates, map(function (predicate) {
            createNetworkParams(hiddenSize, predicates.length, predicate)
        }, predicates))
    };
}

var generateTrainingData = function(listOfLists, fn, numSamples) {
    var recursiveMap = function(listOfLists, fn, numSamples, args /* internal*/) {
        if (listOfLists.length === 0) {
            var resultDist = apply(fn, args);
            return repeat(numSamples, function() {
                return snoc(args, sample(resultDist));
            })
        }

        var restEntries = rest(listOfLists);
        return _.flatten(map(function(e) { 
            recursiveMap(restEntries, fn, numSamples, snoc(args, e))
        }, first(listOfLists)), /*shallow*/ true)
    };
    
    return recursiveMap(listOfLists, fn, numSamples, []);
}

var readOrGenerateTrainingData = function(filename, listOfLists, fn, numSamples) {
    var relativePath = 'qaData/' + filename + '-data.json';
    if (webpplFs.node.existsSync(relativePath)) {
        return json.read(relativePath);
    }

    var data = generateTrainingData(listOfLists, fn, numSamples);
    json.write(relativePath, data);
    return data;
}

var computeAndWriteResults = function(filename, queryAndModelPairs) {
    var results = map(function(queryAndModel) {
        return {
            query: queryAndModel.query,
            result: apply(queryAndModel.model, queryAndModel.query)
        }
    }, queryAndModelPairs);

    json.write('qaExperimentsOutput/' + filename + '-results.json', results);
    return results;
}